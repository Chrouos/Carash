const { Configuration, OpenAIApi } = require("openai");
const CryptoJS = require('crypto-js')
const ConfigCrypto = require('../tools/ConfigCrypto')

var chatRecordTimes = 0;
const ChromaDB_Tools = require('../tools/ChromaTools');

exports.getTemplate = async (req, res) => {
    // + äº¤é€šäº‹æ•…çš„æ•˜è¿° -> æ­¸ç´æˆ Json çš„æ ¼å¼

    try {

        const requestData = req.body; // Data from the request.
        console.log("ğŸš€ ~ file: chatGPTController.js:11 ~ exports.getTemplate= ~ requestData:", requestData)
        chatRecordTimes += 1;

        // Decrypt
        const configCrypto = new ConfigCrypto();
        const OPENAI_API_KEY = configCrypto.config.GPT_KEY; // Get OpenAI API key
        console.log(`After decrypt => ${OPENAI_API_KEY}`)

        const configuration = new Configuration({
            apiKey: OPENAI_API_KEY
        });

        const openai = new OpenAIApi(configuration);
        let jsonResponseData;

        if (chatRecordTimes = 1) {

            const firstmessages = [
                {
                    "role": "system",
                    "content": "ä½ ç¾åœ¨æ˜¯ä¸€ä»¶äº¤é€šè«®è©¢çš„å°ˆå®¶ï¼Œç¾åœ¨æœ‰ä¸€ä»¶äº¤é€šäº‹æ•…çš„æ•˜è¿°ï¼Œè«‹ä½ å°‡è³‡è¨Šæ­¸ç´æˆå¦‚ä¸‹çš„jsonæ ¼å¼ï¼Œå¦‚æœæ²’æœ‰è³‡æ–™è«‹ä¿æŒæ¬„ä½ç©ºç™½ã€‚{\"ç™¼ç”Ÿæ—¥æœŸ\": \"\",\"ç™¼ç”Ÿæ™‚é–“\": \"\",\"ç™¼ç”Ÿåœ°é»\": \"\",\"è¢«å‘Šé§•é§›äº¤é€šå·¥å…·\": \"\",\"åŸå‘Šé§•é§›äº¤é€šå·¥å…·\": \"\",\"å‡ºç™¼åœ°\": \"\",\"è¡Œé§›é“è·¯\": \"\",\"è¡Œé€²æ–¹å‘\": \"\",\"äº‹ç™¼ç¶“é\": \"\",\"è¡Œé€²æ–¹å‘çš„è™ŸèªŒ\": \"\",\"å¤©å€™\": \"\",\"è·¯æ³\": \"\",\"è¡Œè»Šé€Ÿåº¦\": \"\",\"è¢«å‘Šè»Šè¼›æå£æƒ…å½¢\": \"\",\"åŸå‘Šè»Šè¼›æå£æƒ…å½¢\": \"\",\"è¢«å‘Šå‚·å‹¢\": \"\",\"åŸå‘Šå‚·å‹¢\": \"\"}"
                },
            ]
            firstmessages.push(...requestData);
            //console.log(firstmessages);

            const firstResponse = await openai.createChatCompletion({
                model: "gpt-3.5-turbo",
                messages: firstmessages,
                temperature: 0.1,
                max_tokens: 1024,
                top_p: 1,
                frequency_penalty: 0,
                presence_penalty: 0,
            });

            jsonResponseData = firstResponse.data.choices[0].message;
            //console.log("ğŸš€ ~ file: chatGPTController.js:34 ~ exports.getTemplate= ~ firstResponse.data.choices[0].message:\n", firstResponse.data.choices[0].message)

        }
        else {

            const jsonMessage = [{
                "role": "system",
                "content": "ç¾åœ¨æœ‰ä¸€å€‹å›ç­”ï¼Œæ˜¯é‡å°ä»¥ä¸‹jsonæ ¼å¼çš„ç¬¬ä¸€å€‹æ²’æœ‰å€¼çš„keyï¼Œè«‹ä¾ç…§æ­¤Jsonæ ¼å¼å¡«å…¥ç´æ ¼æ²’æœ‰å€¼çš„keyä¸­ï¼Œä¸¦ä¸”å›è¦†æ•´å€‹Jsonæ ¼å¼ï¼Œè‹¥ä½¿ç”¨è€…å›è¦†ä¸çŸ¥é“æˆ–å¿˜è¨˜äº†è«‹å¡«å…¥'æœªçŸ¥'ã€‚è«‹ä¸è¦å¡«å…¥ä¸ç›¸é—œçš„keyä¸­ã€‚"
            }]
            jsonMessage.push(...requestData);

            const jsonResponse = await openai.createChatCompletion({
                model: "gpt-3.5-turbo",
                messages: jsonMessage,
                temperature: 0.1,
                max_tokens: 1024,
                top_p: 1,
                frequency_penalty: 0,
                presence_penalty: 0
            });

            jsonResponseData = jsonResponse.data.choices[0].message;
            //console.log("ğŸš€ ~ file: chatGPTController.js:34 ~ exports.getTemplate= ~ jsonResponse.data.choices[0].message:\n", jsonResponse.data.choices[0].message)

        }


        const questionMessage = [{
            "role": "system",
            "content": "ä½ ç¾åœ¨æ˜¯ä¸€å€‹äº¤é€šäº‹æ•…è«®è©¢çš„æ©Ÿå™¨äººï¼Œè«‹ä¾ç…§JSONæ ¼å¼ä¸­ç¬¬ä¸€å€‹æ²’æœ‰å€¼çš„keyï¼Œç”¢ç”Ÿä¸€å€‹è©¢å•æ­¤keyçš„å•é¡Œã€‚"
        }]
        questionMessage.push(jsonResponseData);

        //console.log("questionMessage : ", questionMessage);

        const questionResponse = await openai.createChatCompletion({
            model: "gpt-3.5-turbo",
            messages: questionMessage,
            temperature: 0.1,
            max_tokens: 1024,
            top_p: 1,
            frequency_penalty: 0,
            presence_penalty: 0
        });

        const gptResponse = [questionResponse.data.choices[0].message];
        gptResponse.push(jsonResponseData);

        console.log("ğŸš€ ~ file: chatGPTController.js:158 ~ exports.getTemplate= ~ gptResponse:", gptResponse)
        res.status(200).send(gptResponse);


    } catch (error) {
        console.error("Error fetching from OpenAI:", error.message || error);
        res.status(500).send(`Error fetching from OpenAI: ${error.message || error}`);

    }
};


// response.data.choices[0].message
exports.chat_test = async (req, res) => {
    // + èˆ‡å‰ç«¯çš„èŠå¤©æ¸¬è©¦

    try {
        const requestData = req.body; // Data from the request.
        console.log("ğŸš€ ~ file: chatGPTController.js:71 ~ exports.chat_test= ~ requestData:", requestData)

        const messageList = [{
            "role": "user",
            "content": requestData.content
        }]

        // Decrypt
        const en_OPENAI_API_KEY = config.get('chatGPT.key');
        const OPENAI_API_KEY = CryptoJS.AES.decrypt(en_OPENAI_API_KEY, "").toString(CryptoJS.enc.Utf8)
        console.log(`After decrypt => ${OPENAI_API_KEY}`)

        const configuration = new Configuration({
            apiKey: OPENAI_API_KEY
        });

        const openai = new OpenAIApi(configuration);

        // ! ç”¢ç”Ÿå¯èƒ½æœƒéœ€è¦ä¸€é»æ™‚é–“
        const response = await openai.createChatCompletion({
            model: "gpt-3.5-turbo",
            messages: messageList,
            temperature: 0.1,
            max_tokens: 1024,
            top_p: 1,
            frequency_penalty: 0,
            presence_penalty: 0
        });

        console.log("ğŸš€ ~ file: chatGPTController.js:34 ~ exports.getTemplate= ~ response.data.choices[0].message:\n", response.data.choices[0].message)
        res.status(200).send(response.data.choices[0].message.content);

    } catch (error) {
        console.error("Error fetching from OpenAI:", error.message || error);
        res.status(500).send(`Error fetching from OpenAI: ${error.message || error}`);

    }
};

exports.getTitle = async(req, res) => {
    try {
        const chromadb = new ChromaDB_Tools("Traffic_Advisory");
        const titles = await chromadb.peek();
        const responseData = titles.ids.map((id, index) => {
            return Object.assign({}, {id: id}, titles.metadatas[index]);
        });

        res.status(200).send(responseData);
    }
    catch (error) {
        console.error("[getTitle] Error :", error.message || error);
        res.status(500).send(`[getTitle] Error : ${error.message || error}`);
    }
}


exports.templateJSON = async (req, res) => {
    /*
        ResponseData.
            content,
            incidentJson,
            title,
            ids,
            totalContent
    */

    try {

        // - ç²å¾— OpenAI API
        const configCrypto = new ConfigCrypto();
        const OPENAI_API_KEY = configCrypto.config.GPT_KEY; // Get OpenAI API key
        const openai = new OpenAIApi(new Configuration({ apiKey: OPENAI_API_KEY })); // openAI API

        // - å›å‚³è³‡è¨Š
        var responseData = req.body;
        const userContent = req.body.content;

        // - æ•´ç† request data
        const requestData = req.body;   
        const notNullCount = Object.values(responseData.incidentJson).filter(value => value !== "").length; // ç›®å‰ä¸æ˜¯ Null çš„å€¼

        // - å‘¼å«è³‡æ–™åº« ChromaDB
        const chromadb = new ChromaDB_Tools("Traffic_Advisory");
        const chromadb_json = new ChromaDB_Tools("Traffic_Advisory_Json");
        const chromadb_content = new ChromaDB_Tools("Traffic_Advisory_Content");
        var chromadbRequest = {};

        // - ç›®å‰é‚„æœªæœ‰ä»»ä½•è³‡è¨Š: ç¬¬ä¸€æ¬¡å°è©±
        if (notNullCount == 0) {

            const firstMessages = [
                { "role": "system", "content": "ä½ ç¾åœ¨æ˜¯ä¸€ä»¶äº¤é€šè«®è©¢çš„å°ˆå®¶ï¼Œç¾åœ¨æœ‰ä¸€ä»¶äº¤é€šäº‹æ•…çš„æ•˜è¿°ï¼Œè«‹ä½ å°‡è³‡è¨Šæ­¸ç´æˆå¦‚ä¸‹çš„jsonæ ¼å¼ï¼Œå¦‚æœæ²’æœ‰è³‡æ–™è«‹ä¿æŒæ¬„ä½ç©ºç™½ï¼Œæ­¸ç´çš„è³‡è¨Šè«‹èªªæ˜æˆé¡åˆ¤æ±ºæ›¸æ ¼å¼ã€‚æˆ‘ = åŸå‘Šï¼Œå°æ–¹ = è¢«å‘Š" + JSON.stringify(requestData.incidentJson) },
                { "role": "user", "content": requestData.content }
            ]

            const gptResponse = await openai.createChatCompletion({
                model: "gpt-3.5-turbo",
                messages: firstMessages,
                temperature: 0.1,
                max_tokens: 1024,
                top_p: 1,
                frequency_penalty: 0,
                presence_penalty: 0,
            });

            // å›å‚³çš„æœ‰å¯èƒ½ä¸æ˜¯ JSON
            try {
                responseData.incidentJson = JSON.parse(gptResponse.data.choices[0].message.content);
                responseData.ids = await chromadb.nextIds();
            } catch (error) {
                console.error("Error parsing JSON:", error);
            }
        }

        // - å·²ç¶“æœ‰éƒ¨åˆ†è³‡è¨Šäº†: è©¢å•é‚„æœªçŸ¥æ›‰çš„è³‡è¨Š (GPT - 1)
        else {

            const tidyMessage = [
                { "role": "system", "content": "ä½ æ˜¯ä¸€ä½äº‹ä»¶æ“·å–æ©Ÿå™¨äººï¼Œç¾åœ¨æœ‰ä¸€å€‹æè¿°æ˜¯é‡å°ä»¥ä¸‹jsonæ ¼å¼ä¸­ç©ºç™½valueçš„å›ç­”ï¼Œè«‹åŠ å…¥ä»¥ä¸‹æ•´å€‹Jsonï¼Œä¸¦ä¸”ä¾ç…§Jsonæ ¼å¼å›è¦†ï¼Œå¦‚æœæ²’æœ‰è³‡æ–™è«‹ä¿ç•™ç©ºç™½å€¼ï¼Œè‹¥ä½¿ç”¨è€…å›è¦†ä¸çŸ¥é“æˆ–å¿˜è¨˜äº†è«‹å¡«å…¥'æœªçŸ¥'ï¼Œè«‹ä¸è¦æ›´æ”¹æˆ–å¡«å…¥ä¸ç›¸é—œçš„keyä¸­ã€‚" + JSON.stringify(requestData.incidentJson) },
                { "role": "user", "content": requestData.content } // æŠŠç›®å‰è»Šç¦ç›¸é—œçš„ JSON èˆ‡ ä½¿ç”¨è€…å›è¦†ä¸²æ¥
            ]

            const gptResponse = await openai.createChatCompletion({
                model: "gpt-3.5-turbo",
                messages: tidyMessage,
                temperature: 0.1,
                max_tokens: 1024,
                top_p: 1,
                frequency_penalty: 0,
                presence_penalty: 0,
            });

            // å›å‚³çš„æœ‰å¯èƒ½ä¸æ˜¯ JSON
            try {
                responseData.incidentJson = JSON.parse(gptResponse.data.choices[0].message.content);
            } catch (error) {
                console.error("Error parsing JSON:", error);
            }
        }

        // - æœ€å¾Œ GPT çš„å›è¦†æ ¼å¼
        const questionMessage = [
            { "role": "system", "content": "ä½ ç¾åœ¨æ˜¯ä¸€å€‹äº¤é€šäº‹æ•…è«®è©¢çš„æ©Ÿå™¨äººï¼Œè«‹ä¾ç…§JSONæ ¼å¼ä¸­ç¬¬ä¸€å€‹æ²’æœ‰valueçš„keyï¼Œç”¢ç”Ÿä¸€å€‹è©¢å•æ­¤keyçš„å•é¡Œã€‚è«‹ä¸è¦å›ç­”å•é¡Œä»¥å¤–çš„æ±è¥¿ï¼Œä½ åªéœ€è¦æå•å°±å¥½ã€‚" },
            { "role": "user", "content": JSON.stringify(requestData.incidentJson) }
        ]

        const gptResponse = await openai.createChatCompletion({
            model: "gpt-3.5-turbo",
            messages: questionMessage,
            temperature: 0.1,
            max_tokens: 1024,
            top_p: 1,
            frequency_penalty: 0,
            presence_penalty: 0,
        });
        const responseContent = gptResponse.data.choices[0].message.content;

        // - å›å‚³çµæœ
        responseData.content = responseContent;
        const newContent = [
            {ids: responseData.ids, character: 'questioner', value: userContent, createTime: '2023-07-18T05:44:00'},
            {ids: responseData.ids, character: 'chatBot', value: responseContent, createTime: '2023-07-18T05:44:00'}
        ]
        responseData.totalContent.push(
            {character: 'questioner', value: userContent, createTime: '2023-07-18T05:44:00'},
            {ids: responseData.ids, character: 'chatBot', value: responseContent, createTime: '2023-07-18T05:44:00'});

        // - å„²å­˜è‡³è³‡æ–™åº«å…§éƒ¨
        if (notNullCount === 0){
            chromadb.add({
                ids: responseData.ids,
                metadatas: [{title: responseData.title || "ChatBox"}],
                documents: responseData.title || "ChatBox"
            })
            chromadb_json.add({
                ids: responseData.ids,
                metadatas: [responseData.incidentJson],
                documents: responseData.incidentJson['äº‹ç™¼ç¶“é']
            })
        }
        else{
            chromadb.update({
                ids: responseData.ids,
                metadatas: [{title: responseData.title}],
                documents: responseData.title
            })
            chromadb_json.update({
                ids: responseData.ids,
                metadatas: [responseData.incidentJson],
                documents: responseData.incidentJson['äº‹ç™¼ç¶“é']
            })
        }
        
        chromadb_content.add({
            metadatas: newContent,
            documents: [userContent, responseContent],
        })
        
        res.status(200).send(responseData);

    } catch (error) {
        console.error("[templateJSON] Error fetching from OpenAI:", error.message || error);
        res.status(500).send(`[templateJSON] Error fetching from OpenAI: ${error.message || error}`);
    }
};


/*

1:
108å¹´4æœˆ30æ—¥ï¼Œå¤§æ¦‚æ—©ä¸Šåé»å¤šçš„æ™‚å€™ï¼Œæˆ‘é¨é‡æ©Ÿåœ¨ä¸­å±±è·¯é™„è¿‘è¡Œé§›ã€‚æœ‰å°è½è»Šæ²’æœ‰éµå®ˆäº¤é€šè™ŸèªŒï¼Œé—–ç´…ç‡ˆï¼Œæ’åˆ°æˆ‘å®³æˆ‘å€’åœ°ï¼Œå·¦é‚Šè†è“‹é–‹æ”¾æ€§éª¨æŠ˜é‚„æœ‰å¾ˆå¤šæ“¦å‚·ã€‚

2:
æˆ‘å¾åŒ—æŠ•å€å‡ºç™¼ï¼Œæˆ‘æ˜¯ç¶ ç‡ˆï¼Œé‚£å¤©å¤©æ°£æ™´æœ—ï¼Œè·¯æ³æ­£å¸¸ï¼Œæˆ‘ç•¶æ™‚è¡Œé§›è»Šé€Ÿå¤§ç´„50å…¬é‡Œï¼Œæˆ‘çš„è»Šå¾Œç‡ˆæå£åŠè»Šèº«æœ‰äº›æ“¦å‚·ã€‚

*/