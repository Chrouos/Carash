const { Configuration, OpenAIApi } = require("openai");
const CryptoJS = require('crypto-js')
const defaultConfig = require('../config/development');    // * Config æª”æ¡ˆ

var chatRecordTimes = 0;
var questionMessage = [{
    "role": "",
    "content": ""
}]
var answerMessage = [{
    "role": "",
    "content": ""
}]

const lawJson = {
    "ç™¼ç”Ÿæ—¥æœŸ": "",
    "ç™¼ç”Ÿæ™‚é–“": "",
    "ç™¼ç”Ÿåœ°é»": "",
    "è¢«å‘Šé§•é§›äº¤é€šå·¥å…·": "",
    "åŸå‘Šé§•é§›äº¤é€šå·¥å…·": "",
    "å‡ºç™¼åœ°": "",
    "è¡Œé§›é“è·¯": "",
    "è¡Œé€²æ–¹å‘": "",
    "äº‹ç™¼ç¶“é": "",
    "è¡Œé€²æ–¹å‘çš„è™ŸèªŒ": "",
    "å¤©å€™": "",
    "è·¯æ³": "",
    "è¡Œè»Šé€Ÿåº¦": "",
    "è¢«å‘Šè»Šè¼›æå£æƒ…å½¢": "",
    "åŸå‘Šè»Šè¼›æå£æƒ…å½¢": "",
    "è¢«å‘Šå‚·å‹¢": "",
    "åŸå‘Šå‚·å‹¢": ""
}
var myJson = lawJson;

exports.getTemplate = async (req, res) => {
    // + äº¤é€šäº‹æ•…çš„æ•˜è¿° -> æ­¸ç´æˆ Json çš„æ ¼å¼

    try {

        const requestData = req.body; // Data from the request.
        console.log("ğŸš€ ~ file: chatGPTController.js:11 ~ exports.getTemplate= ~ requestData:", requestData)
        chatRecordTimes += 1;

        // Decrypt
        const en_OPENAI_API_KEY = defaultConfig.GPT_KEY;
        const OPENAI_API_KEY = CryptoJS.AES.decrypt(en_OPENAI_API_KEY, "").toString(CryptoJS.enc.Utf8)
        console.log(`After decrypt => ${OPENAI_API_KEY}`)

        const configuration = new Configuration({
            apiKey: OPENAI_API_KEY
        });

        const openai = new OpenAIApi(configuration);

        if (chatRecordTimes = 1) {

            const firstmessages = [
                {
                    "role": "system",
                    "content": "ä½ ç¾åœ¨æ˜¯ä¸€ä»¶äº¤é€šè«®è©¢çš„å°ˆå®¶ï¼Œç¾åœ¨æœ‰ä¸€ä»¶äº¤é€šäº‹æ•…çš„æ•˜è¿°ï¼Œè«‹ä½ å°‡è³‡è¨Šæ­¸ç´æˆå¦‚ä¸‹çš„jsonæ ¼å¼ï¼Œå¦‚æœæ²’æœ‰è³‡æ–™è«‹ä¿æŒæ¬„ä½ç©ºç™½ã€‚{\"ç™¼ç”Ÿæ—¥æœŸ\": \"\",\"ç™¼ç”Ÿæ™‚é–“\": \"\",\"ç™¼ç”Ÿåœ°é»\": \"\",\"è¢«å‘Šé§•é§›äº¤é€šå·¥å…·\": \"\",\"åŸå‘Šé§•é§›äº¤é€šå·¥å…·\": \"\",\"å‡ºç™¼åœ°\": \"\",\"è¡Œé§›é“è·¯\": \"\",\"è¡Œé€²æ–¹å‘\": \"\",\"äº‹ç™¼ç¶“é\": \"\",\"è¡Œé€²æ–¹å‘çš„è™ŸèªŒ\": \"\",\"å¤©å€™\": \"\",\"è·¯æ³\": \"\",\"è¡Œè»Šé€Ÿåº¦\": \"\",\"è¢«å‘Šè»Šè¼›æå£æƒ…å½¢\": \"\",\"åŸå‘Šè»Šè¼›æå£æƒ…å½¢\": \"\",\"è¢«å‘Šå‚·å‹¢\": \"\",\"åŸå‘Šå‚·å‹¢\": \"\"}"
                },
            ]

            firstmessages.push({ "role": "user", "content": requestData.content });

            const firstResponse = await openai.createChatCompletion({
                model: "gpt-3.5-turbo",
                messages: firstmessages,
                temperature: 0.1,
                max_tokens: 1024,
                top_p: 1,
                frequency_penalty: 0,
                presence_penalty: 0,
            });

            const jsonResponseData = JSON.parse(firstResponse.data.choices[0].message.content);
            console.log("jasonResponseData is :", jsonResponseData);

            for (const key in jsonResponseData) {
                if (jsonResponseData.hasOwnProperty(key)) {
                    myJson[key] = jsonResponseData[key];
                }
            }

            console.log("ğŸš€ ~ file: chatGPTController.js:34 ~ exports.getTemplate= ~ firstResponse.data.choices[0].message:\n", firstResponse.data.choices[0].message)

        }
        else {

            answerMessage.push({ "role": "user", "content": requestData.content });

            const jsonResponse = await openai.createChatCompletion({
                model: "gpt-3.5-turbo",
                messages: answerMessage,
                temperature: 0.1,
                max_tokens: 1024,
                top_p: 1,
                frequency_penalty: 0,
                presence_penalty: 0
            });

            const jsonResponseData = JSON.parse(jsonResponse.data.choices[0].message.content);
            console.log("jasonResponseData is :", jsonResponseData);

            for (const key in jsonResponseData) {
                if (jsonResponseData.hasOwnProperty(key)) {
                    myJson[key] = jsonResponseData[key];
                }
            }

            console.log("ğŸš€ ~ file: chatGPTController.js:34 ~ exports.getTemplate= ~ jsonResponse.data.choices[0].message:\n", jsonResponse.data.choices[0].message)

        }


        for (const key in myJson) {
            if (myJson.hasOwnProperty(key)) {
                if (myJson[key].trim().length === 0) {

                    console.log(`"${key}"çš„å€¼ç‚ºç©º`);

                    questionMessage = [{
                        "role": "system",
                        "content": `ä½ ç¾åœ¨æ˜¯ä¸€å€‹äº¤é€šäº‹æ•…è«®è©¢çš„æ©Ÿå™¨äººï¼Œè«‹ç”¢ç”Ÿä¸€å€‹è©¢å•"${key}"çš„æå•`
                    }]
                    answerMessage = [{
                        "role": "system",
                        "content": `ç¾åœ¨æœ‰ä¸€å€‹é—œæ–¼"${key}"çš„æè¿°ï¼Œè‹¥ä½¿ç”¨è€…å›è¦†ä¸çŸ¥é“æˆ–å¿˜è¨˜è«‹å¡«å…¥"æœªçŸ¥"è«‹ä¾ç…§ä»¥ä¸‹json æ ¼å¼å›è¦†ï¼š{â€œ${key}â€ï¼š}`
                    }]

                    break;

                }
                else {

                    console.log(`"${key}"çš„å€¼ç‚ºä¸ç‚ºç©º`)
                }
            }
        }

        console.log("questionMessage is : ", questionMessage);
        console.log("questionMessage is : ", answerMessage);


        const questionResponse = await openai.createChatCompletion({
            model: "gpt-3.5-turbo",
            messages: questionMessage,
            temperature: 0.1,
            max_tokens: 1024,
            top_p: 1,
            frequency_penalty: 0,
            presence_penalty: 0
        });

        const gptResponse = questionResponse.data.choices[0].message;
        
        console.log("ğŸš€ ~ file: chatGPTController.js:158 ~ exports.getTemplate= ~ gptResponse:", gptResponse)
        res.status(200).send(gptResponse.content);


    } catch (error) {
        console.error("Error fetching from OpenAI:", error.message || error);
        res.status(500).send(`Error fetching from OpenAI: ${error.message || error}`);

    }
};


// response.data.choices[0].message
exports.chat_test = async (req, res) => {
    // + èˆ‡å‰ç«¯çš„èŠå¤©æ¸¬è©¦

    try {
        const requestData = req.body; // Data from the request.
        console.log("ğŸš€ ~ file: chatGPTController.js:71 ~ exports.chat_test= ~ requestData:", requestData)

        const messageList = [{
            "role": "user",
            "content": requestData.content
        }]

        // Decrypt
        const en_OPENAI_API_KEY = config.get('chatGPT.key');
        const OPENAI_API_KEY = CryptoJS.AES.decrypt(en_OPENAI_API_KEY, "").toString(CryptoJS.enc.Utf8)
        console.log(`After decrypt => ${OPENAI_API_KEY}`)

        const configuration = new Configuration({
            apiKey: OPENAI_API_KEY
        });

        const openai = new OpenAIApi(configuration);

        // ! ç”¢ç”Ÿå¯èƒ½æœƒéœ€è¦ä¸€é»æ™‚é–“
        const response = await openai.createChatCompletion({
            model: "gpt-3.5-turbo",
            messages: messageList,
            temperature: 0.1,
            max_tokens: 1024,
            top_p: 1,
            frequency_penalty: 0,
            presence_penalty: 0
        });

        console.log("ğŸš€ ~ file: chatGPTController.js:34 ~ exports.getTemplate= ~ response.data.choices[0].message:\n", response.data.choices[0].message)
        res.status(200).send(response.data.choices[0].message.content);

    } catch (error) {
        console.error("Error fetching from OpenAI:", error.message || error);
        res.status(500).send(`Error fetching from OpenAI: ${error.message || error}`);

    }
};


/*

108å¹´4æœˆ30æ—¥ï¼Œå¤§æ¦‚æ—©ä¸Šåé»å¤šçš„æ™‚å€™ï¼Œæˆ‘é¨é‡æ©Ÿåœ¨ä¸­å±±è·¯é™„è¿‘è¡Œé§›ã€‚
æœ‰å°è»Šæ²’æœ‰éµå®ˆäº¤é€šè™ŸèªŒï¼Œé—–ç´…ç‡ˆï¼Œæ’åˆ°æˆ‘å®³æˆ‘å€’åœ°ï¼Œå·¦é‚Šè†è“‹é–‹æ”¾æ€§éª¨æŠ˜é‚„æœ‰å¾ˆå¤šæ“¦å‚·ã€‚

*/